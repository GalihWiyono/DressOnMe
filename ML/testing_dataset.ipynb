{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "SHAPE = 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining a frame for image and mask storage\n",
    "framObjTrain = {'img' : [],\n",
    "           'mask' : []\n",
    "          }\n",
    "\n",
    "framObjValidation = {'img' : [],\n",
    "           'mask' : []\n",
    "          }\n",
    "\n",
    "## defining data Loader function\n",
    "def LoadData( frameObj = None, imgPath = None, maskPath = None, shape = SHAPE): ### !!! SPLIT DATASET\n",
    "    imgNames = os.listdir(imgPath)\n",
    "    maskNames = []\n",
    "    \n",
    "    ## generating mask names\n",
    "    for mem in imgNames:\n",
    "        maskNames.append(re.sub('\\.jpg', '.png', mem))\n",
    "    \n",
    "    ## defining images and labels path\n",
    "    imgAddr = imgPath + '/'\n",
    "    maskAddr = maskPath + '/'\n",
    "    \n",
    "    ## loop all images\n",
    "    for i in range (len(imgNames)):\n",
    "        try:\n",
    "            ## read an image and the corresponding label\n",
    "            img = plt.imread(imgAddr + imgNames[i])\n",
    "            mask = plt.imread(maskAddr + maskNames[i])\n",
    "            \n",
    "            ## normalize image color\n",
    "            img = img/255.0\n",
    "            \n",
    "            ## resize image dimension to SHAPE x SHAPE\n",
    "            img = cv2.resize(img, (shape, shape))\n",
    "            mask = cv2.resize(mask, (shape, shape))\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "        frameObj['img'].append(img)\n",
    "        frameObj['mask'].append(mask)\n",
    "        \n",
    "    return frameObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "framObjTrain = LoadData( framObjTrain, ### !!! IMPLEMENT CHANGED METHOD\n",
    "                        imgPath = 'dataset/images', \n",
    "                        maskPath = 'dataset/new_labels',\n",
    "                        shape = SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## displaying data loaded by our function\n",
    "import random\n",
    "n = random.randint(0,100)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(framObjTrain['img'][n])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(framObjTrain['mask'][n])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining our CNN for encoding and decoding\n",
    "\n",
    "myTransformer = tf.keras.models.Sequential([ ### !!! TRY DIFFERENT ARCHITECTURE\n",
    "    ## defining encoder \n",
    "    tf.keras.layers.Input(shape= (SHAPE, SHAPE, 3)),\n",
    "    tf.keras.layers.Conv2D(filters = 16, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size = (2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), strides = (2,2), activation = 'relu', padding = 'valid'),\n",
    "    tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), strides = (2,2), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size = (2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.Conv2D(filters = 256, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.Conv2D(filters = 512, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    \n",
    "    ## defining decoder path\n",
    "    tf.keras.layers.UpSampling2D(size = (2,2)),\n",
    "    tf.keras.layers.Conv2D(filters = 256, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    \n",
    "    tf.keras.layers.UpSampling2D(size = (2,2)),\n",
    "    tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.UpSampling2D(size = (2,2)),\n",
    "    tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.UpSampling2D(size = (2,2)),\n",
    "    tf.keras.layers.Conv2D(filters = 16, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.Conv2D(filters = 3, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    \n",
    "    \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myTransformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTransformer.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 5e-5), ### !!! TRY DIFFERENT ALGORITHM\n",
    "    loss = 'mean_absolute_error', ### !!! TRY DIFFERENT ALGORITHM\n",
    "    metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data\n",
    "retVal = myTransformer.fit(np.array(framObjTrain['img']),\n",
    "                           np.array(framObjTrain['mask']),\n",
    "                           batch_size=16, ### !!! TRY DIFFERENT BATCH SIZE\n",
    "                           ### !!! ADD VALIDATION DATASET\n",
    "                           epochs = 25 ### !!! CHANGE BACK TO 100\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(retVal.history['loss'], label = 'training_loss')\n",
    "plt.plot(retVal.history['acc'], label = 'training_accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict16 (valMap, model, shape = SHAPE):\n",
    "    ## getting and proccessing val data\n",
    "    img = valMap['img']\n",
    "    mask = valMap['mask']\n",
    "    mask = mask[0:16]\n",
    "    \n",
    "    imgProc = img [0:16]\n",
    "    imgProc = np.array(img)\n",
    "    \n",
    "    predictions = model.predict(imgProc)\n",
    "    for i in range(len(predictions)):\n",
    "        predictions[i] = cv2.merge((predictions[i,:,:,0],predictions[i,:,:,1],predictions[i,:,:,2]))\n",
    "    \n",
    "    return predictions, imgProc, mask\n",
    "\n",
    "\n",
    "def Plotter(img, predMask, groundTruth):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    \n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(img)\n",
    "    plt.title('image')\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(predMask)\n",
    "    plt.title('Predicted Mask')\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(groundTruth)\n",
    "    plt.title('actual Mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixteenPrediction, actuals, masks = predict16(framObjTrain, myTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_r = random.randint(0,15)\n",
    "\n",
    "Plotter(actuals[n_r], sixteenPrediction[n_r], masks[n_r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the image, provide window name first\n",
    "cv2.imshow('image window', sixteenPrediction[n_r])\n",
    "# add wait key. window waits until user presses a key\n",
    "cv2.waitKey(0)\n",
    "# and finally destroy/close all open windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_file = 'model.h5'\n",
    "#myTransformer.save(save_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
